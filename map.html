<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">
<title>Markmap</title>
<style>
* {
  margin: 0;
  padding: 0;
}
#mindmap {
  display: block;
  width: 100vw;
  height: 100vh;
}
</style>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/prismjs@1.28.0/themes/prism.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/markmap-toolbar@0.14.4/dist/style.css">
</head>
<body>
<svg id="mindmap"></svg>
<script src="https://cdn.jsdelivr.net/npm/d3@6.7.0"></script><script src="https://cdn.jsdelivr.net/npm/markmap-view@0.14.4"></script><script src="https://cdn.jsdelivr.net/npm/markmap-toolbar@0.14.4/dist/index.umd.min.js"></script><script>(r => {
                setTimeout(r);
              })(() => {
  const {
    markmap,
    mm
  } = window;
  const toolbar = new markmap.Toolbar();
  toolbar.attach(mm);
  const el = toolbar.render();
  el.setAttribute('style', 'position:absolute;bottom:20px;right:20px');
  document.body.append(el);
})</script><script>((getMarkmap, getOptions, root, jsonOptions) => {
        const markmap = getMarkmap();
        window.mm = markmap.Markmap.create('svg#mindmap', (getOptions || markmap.deriveOptions)(jsonOptions), root);
      })(() => window.markmap,null,{"type":"root","depth":0,"content":"","children":[{"type":"paragraph","depth":1,"payload":{"lines":[14,15]},"content":"[TOC]"},{"type":"paragraph","depth":1,"payload":{"lines":[16,17]},"content":"本报告使用了PDF书签，建议打开，可以快速跳转到不同章节"},{"type":"paragraph","depth":1,"payload":{"lines":[18,19]},"content":"<strong>思维导图</strong>"},{"type":"paragraph","depth":1,"payload":{"lines":[20,21]},"content":"<img src=\"./assets/未命名文件.jpg\" alt=\"未命名文件\">"},{"type":"heading","depth":1,"payload":{"lines":[22,23]},"content":"一、HADOOP MAPREDUCE WORDCOUNT案例实现","children":[{"type":"heading","depth":2,"payload":{"lines":[24,25]},"content":"1、按照实验二的方法创建 java 项目并配置 Maven。","children":[{"type":"fence","depth":3,"content":"<pre class=\"language-xml\"><code class=\"language-xml\"><span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>mirror</span><span class=\"token punctuation\">></span></span>\n    <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>id</span><span class=\"token punctuation\">></span></span>alimaven<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>id</span><span class=\"token punctuation\">></span></span>\n    <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>mirrorOf</span><span class=\"token punctuation\">></span></span>central<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>mirrorOf</span><span class=\"token punctuation\">></span></span>\n    <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>name</span><span class=\"token punctuation\">></span></span>aliyun maven<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>name</span><span class=\"token punctuation\">></span></span>\n    <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>url</span><span class=\"token punctuation\">></span></span>http://maven.aliyun.com/nexus/content/repositories/central/<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>url</span><span class=\"token punctuation\">></span></span>\n<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>mirror</span><span class=\"token punctuation\">></span></span>\n<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>mirror</span><span class=\"token punctuation\">></span></span>\n    <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>id</span><span class=\"token punctuation\">></span></span>aliyunmaven<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>id</span><span class=\"token punctuation\">></span></span>\n    <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>mirrorOf</span><span class=\"token punctuation\">></span></span>*<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>mirrorOf</span><span class=\"token punctuation\">></span></span>\n    <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>name</span><span class=\"token punctuation\">></span></span>阿里云公共仓库<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>name</span><span class=\"token punctuation\">></span></span>\n    <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>url</span><span class=\"token punctuation\">></span></span>https://maven.aliyun.com/repository/public<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>url</span><span class=\"token punctuation\">></span></span>\n<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>mirror</span><span class=\"token punctuation\">></span></span>\n</code></pre>\n"},{"type":"fence","depth":3,"content":"<pre class=\"language-xml\"><code class=\"language-xml\"><span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>localRepository</span><span class=\"token punctuation\">></span></span>你自己的本地仓库路径<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>localRepository</span><span class=\"token punctuation\">></span></span>\n</code></pre>\n"}]},{"type":"heading","depth":2,"payload":{"lines":[55,56]},"content":"2、pom.xml 文件","children":[{"type":"heading","depth":3,"payload":{"lines":[63,64]},"content":"<strong><em>出现的问题:找不到插件</em></strong>"}]},{"type":"heading","depth":2,"payload":{"lines":[85,86]},"content":"3、编写 Mapper、Reducer、Main 代码"},{"type":"heading","depth":2,"payload":{"lines":[97,98]},"content":"4、将程序打成 jar 包","children":[{"type":"list_item","depth":3,"payload":{"lines":[111,112]},"content":"clean：清除之前构建生成的所有文件，即 target 目录及目录下所有文件"},{"type":"list_item","depth":3,"payload":{"lines":[112,113]},"content":"validate：验证项目的正确性"},{"type":"list_item","depth":3,"payload":{"lines":[113,114]},"content":"compile：编译整个项目的源代码，Java 文件"},{"type":"list_item","depth":3,"payload":{"lines":[114,115]},"content":"test：测试 compile 中编译出的代码"},{"type":"list_item","depth":3,"payload":{"lines":[115,116]},"content":"package：打包 compile 中编译的代码，分类到文件夹内，即生成 target 目录及目录下的内容"},{"type":"list_item","depth":3,"payload":{"lines":[116,117]},"content":"verify：验证 test 的结果是否符合标准"},{"type":"list_item","depth":3,"payload":{"lines":[117,118]},"content":"install：将包安装到本地供其他项目使用"},{"type":"list_item","depth":3,"payload":{"lines":[118,119]},"content":"site：生成项目的站点文档"},{"type":"list_item","depth":3,"payload":{"lines":[119,120]},"content":"deploy：将包复制到远程仓库"}]},{"type":"heading","depth":2,"payload":{"lines":[129,130]},"content":"5、上传 jar 包到配置有 hadoop 环境中。"}]},{"type":"heading","depth":1,"payload":{"lines":[151,152]},"content":"二、<em>Spark</em>伪分布式环境配置","children":[{"type":"heading","depth":2,"payload":{"lines":[153,154]},"content":"1、安装 Scala","children":[{"type":"heading","depth":3,"payload":{"lines":[155,156]},"content":"（1）下载安装","children":[{"type":"fence","depth":4,"content":"<pre class=\"language-shell\"><code class=\"language-shell\"><span class=\"token builtin class-name\">cd</span> ~  \n<span class=\"token function\">wget</span> https://downloads.lightbend.com/scala/2.12.15/scala-2.12.15.tgz\n</code></pre>\n"}]},{"type":"heading","depth":3,"payload":{"lines":[164,165]},"content":"（2）解压","children":[{"type":"fence","depth":4,"content":"<pre class=\"language-shell\"><code class=\"language-shell\"><span class=\"token function\">tar</span> <span class=\"token parameter variable\">-zxvf</span> scala-2.12.15.tgz\n<span class=\"token function\">mv</span> scala-2.12.15 /usr/scala-2.12.15\n</code></pre>\n"}]},{"type":"heading","depth":3,"payload":{"lines":[171,172]},"content":"（3）环境变量","children":[{"type":"fence","depth":4,"content":"<pre class=\"language-shell\"><code class=\"language-shell\"><span class=\"token function\">vim</span> /etc/profile\n</code></pre>\n"},{"type":"fence","depth":4,"content":"<pre class=\"language-shell\"><code class=\"language-shell\"><span class=\"token function\">vim</span> ~/.zshrc \n</code></pre>\n"},{"type":"fence","depth":4,"content":"<pre class=\"language-properties\"><code class=\"language-properties\"><span class=\"token key attr-name\">export</span> <span class=\"token value attr-value\">SCALA_HOME=/usr/scala-2.12.15</span>\n<span class=\"token key attr-name\">export</span> <span class=\"token value attr-value\">PATH=$PATH:$SCALA_HOME/bin</span>\n</code></pre>\n"},{"type":"fence","depth":4,"content":"<pre class=\"language-shell\"><code class=\"language-shell\"><span class=\"token builtin class-name\">source</span> ~/.zshrc\n</code></pre>\n"}]},{"type":"heading","depth":3,"payload":{"lines":[198,199]},"content":"（4）检验是否安装成功","children":[{"type":"fence","depth":4,"content":"<pre class=\"language-shell\"><code class=\"language-shell\">scala <span class=\"token parameter variable\">-version</span>\n</code></pre>\n"}]}]},{"type":"heading","depth":2,"payload":{"lines":[206,207]},"content":"2、安装 spark","children":[{"type":"heading","depth":3,"payload":{"lines":[208,209]},"content":"（1）下载 spark 安装包","children":[{"type":"fence","depth":4,"content":"<pre class=\"language-shell\"><code class=\"language-shell\"><span class=\"token builtin class-name\">cd</span> ~ \n<span class=\"token function\">wget</span> https://dlcdn.apache.org/spark/spark-3.2.3/spark-3.2.3-bin-without-hadoop.tgz\n</code></pre>\n"},{"type":"fence","depth":4,"content":"<pre class=\"language-shell\"><code class=\"language-shell\"><span class=\"token function\">wget</span> https://dlcdn.apache.org/spark/spark-3.2.4/spark-3.2.4-bin-without-hadoop.tgz\n</code></pre>\n"}]},{"type":"heading","depth":3,"payload":{"lines":[229,230]},"content":"（2）解压安装包，移动位置，重命名。","children":[{"type":"fence","depth":4,"content":"<pre class=\"language-shell\"><code class=\"language-shell\"><span class=\"token builtin class-name\">cd</span> ~\n<span class=\"token function\">tar</span> <span class=\"token parameter variable\">-zxf</span> spark-3.2.3-bin-without-hadoop.tgz\n<span class=\"token function\">mv</span> spark-3.2.3-bin-without-hadoop /opt/spark\n</code></pre>\n"}]},{"type":"heading","depth":3,"payload":{"lines":[241,242]},"content":"（3）配置环境变量","children":[{"type":"fence","depth":4,"content":"<pre class=\"language-shell\"><code class=\"language-shell\"><span class=\"token function\">sudo</span> <span class=\"token function\">vim</span> /etc/profile\n<span class=\"token function\">vi</span> ~/.zshrc\n</code></pre>\n"},{"type":"fence","depth":4,"content":"<pre class=\"language-shell\"><code class=\"language-shell\"><span class=\"token builtin class-name\">source</span>  ~/.zshrc\n</code></pre>\n"}]},{"type":"heading","depth":3,"payload":{"lines":[258,259]},"content":"（4）Spark 文件配置","children":[{"type":"heading","depth":4,"payload":{"lines":[260,261]},"content":"a. 配置 <code>spark-env.sh</code> 文件","children":[{"type":"fence","depth":5,"content":"<pre class=\"language-shell\"><code class=\"language-shell\"><span class=\"token function\">cp</span>  /opt/spark/conf/spark-env.sh.template  /opt/spark/conf/spark-env.sh\n</code></pre>\n"},{"type":"fence","depth":5,"content":"<pre class=\"language-shell\"><code class=\"language-shell\"><span class=\"token function\">vim</span> /opt/spark/conf/spark-env.sh\n</code></pre>\n"},{"type":"bullet_list","depth":5,"payload":{"lines":[278,286]},"content":"","children":[{"type":"list_item","depth":6,"payload":{"lines":[278,279]},"content":"<code>JAVA_HOME</code> jdk 的安装目录"},{"type":"list_item","depth":6,"payload":{"lines":[279,280]},"content":"<code>SCALA_HOME</code> scala 的安装目录"},{"type":"list_item","depth":6,"payload":{"lines":[280,281]},"content":"<code>HADOOP_CONF_DIR</code> hadoop 的配置文件存放目录"},{"type":"list_item","depth":6,"payload":{"lines":[281,282]},"content":"<code>SPARK_DIST_CLASSPATH</code> 有了 SPARK_DIST_CLASSPATH 配置信息以后，Spark就可以读写 Hadoop 分布式文件系统 HDFS"},{"type":"list_item","depth":6,"payload":{"lines":[282,283]},"content":"<code>SPARK_MASTER_IP</code> spark 主节点绑定的地址"},{"type":"list_item","depth":6,"payload":{"lines":[283,284]},"content":"<code>SPARK_MASTER_PORT</code> spark 主节点绑定的端口号"},{"type":"list_item","depth":6,"payload":{"lines":[284,285]},"content":"<code>SPARK_MASTER_WEBUI_PORT</code> spark master 节点的网页端口"}]}]}]},{"type":"heading","depth":3,"payload":{"lines":[286,287]},"content":"（5）启动 spark","children":[{"type":"fence","depth":4,"content":"<pre class=\"language-shell\"><code class=\"language-shell\"><span class=\"token builtin class-name\">cd</span> /opt/spark\nsbin/start-all.sh\n</code></pre>\n"},{"type":"fence","depth":4,"content":"<pre class=\"language-shell\"><code class=\"language-shell\">jps\n</code></pre>\n"}]},{"type":"heading","depth":3,"payload":{"lines":[307,308]},"content":"（6）用自带样例测试","children":[{"type":"bullet_list","depth":4,"payload":{"lines":[313,316]},"content":"","children":[{"type":"list_item","depth":5,"payload":{"lines":[313,314]},"content":"<code>--class</code>: 主类名称，即包含 <code>main</code> 方法的类的完全限定名。"},{"type":"list_item","depth":5,"payload":{"lines":[314,315]},"content":"<code>--master</code>: Spark 集群的URL或运行模式。例如，可以将其设置为 &quot;local&quot; 以在本地运行应用程序，或将其设置为 &quot;spark://HOST:PORT&quot; 以连接到远程 Spark 集群。"}]},{"type":"fence","depth":4,"content":"<pre class=\"language-shell\"><code class=\"language-shell\"><span class=\"token function\">sudo</span> bin/spark-submit  <span class=\"token parameter variable\">--master</span> spark://M2020212185:7077  <span class=\"token parameter variable\">--class</span> org.apache.spark.examples.SparkPi  /opt/spark/examples/jars/spark-examples_2.12-3.2.3.jar <span class=\"token number\">10</span>\n</code></pre>\n"},{"type":"bullet_list","depth":4,"payload":{"lines":[322,328]},"content":"","children":[{"type":"list_item","depth":5,"payload":{"lines":[322,323]},"content":"<code>bin/spark-submit</code>: 提交 Spark 应用程序的命令。"},{"type":"list_item","depth":5,"payload":{"lines":[323,324]},"content":"<code>--master spark://M2020212185:7077</code>: 指定 Spark 集群的 URL。这里的 URL 是 <code>spark://M2020212185:7077</code>，其中 <code>M2020212185</code> 是主机名，<code>7077</code> 是 Spark 主节点的端口号。"},{"type":"list_item","depth":5,"payload":{"lines":[324,325]},"content":"<code>--class org.apache.spark.examples.SparkPi</code>: 指定应用程序的主类名称。在这里，主类是 <code>org.apache.spark.examples.SparkPi</code>，该类包含计算 π 的近似值的代码。"},{"type":"list_item","depth":5,"payload":{"lines":[325,326]},"content":"<code>/opt/spark/examples/jars/spark-examples_2.12-3.2.3.jar</code>: 应用程序的 JAR 文件路径。这里的 JAR 文件是 Spark 示例程序的 JAR 文件，其中包含 <code>SparkPi</code> 类的代码。"},{"type":"list_item","depth":5,"payload":{"lines":[326,327]},"content":"<code>10</code>: 应用程序参数。在这里，它是应用程序将使用的分区数。"}]}]}]},{"type":"heading","depth":2,"payload":{"lines":[348,349]},"content":"3、本地运行 wordcount 程序","children":[{"type":"heading","depth":3,"payload":{"lines":[350,351]},"content":"（1）创建 Maven 工程"},{"type":"heading","depth":3,"payload":{"lines":[354,355]},"content":"（2）配置 Maven"},{"type":"heading","depth":3,"payload":{"lines":[360,361]},"content":"（3）新建文件夹 scala，并且将文件夹设置为 sources root"},{"type":"heading","depth":3,"payload":{"lines":[364,365]},"content":"（4）添加 scala library"},{"type":"heading","depth":3,"payload":{"lines":[382,383]},"content":"（5）添加 scala 插件，先在 settings-plugins 中下载安装"},{"type":"heading","depth":3,"payload":{"lines":[386,387]},"content":"（6）创建 scala class"},{"type":"heading","depth":3,"payload":{"lines":[390,391]},"content":"（7）上传测试文件"},{"type":"heading","depth":3,"payload":{"lines":[396,397]},"content":"（8）代码","children":[{"type":"fence","depth":4,"content":"<pre class=\"language-java\"><code class=\"language-java\"><span class=\"token keyword\">package</span> <span class=\"token namespace\">org<span class=\"token punctuation\">.</span>bupt_2020212185_zy</span>\n\n<span class=\"token keyword\">import</span> <span class=\"token namespace\">org<span class=\"token punctuation\">.</span>apache<span class=\"token punctuation\">.</span>spark<span class=\"token punctuation\">.</span></span><span class=\"token punctuation\">{</span><span class=\"token class-name\">SparkContext</span><span class=\"token punctuation\">,</span> <span class=\"token class-name\">SparkConf</span><span class=\"token punctuation\">}</span>\n\nobject sparkwordcount <span class=\"token punctuation\">{</span>\n\n  def <span class=\"token function\">main</span><span class=\"token punctuation\">(</span>args<span class=\"token operator\">:</span> <span class=\"token class-name\">Array</span><span class=\"token punctuation\">[</span><span class=\"token class-name\">String</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token operator\">:</span> <span class=\"token class-name\">Unit</span> <span class=\"token operator\">=</span> <span class=\"token punctuation\">{</span>\n    val conf <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">SparkConf</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">setAppName</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"WordCount\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">setMaster</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"local\"</span><span class=\"token punctuation\">)</span>\n\n    val sc <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">SparkContext</span><span class=\"token punctuation\">(</span>conf<span class=\"token punctuation\">)</span>\n\n    val lines <span class=\"token operator\">=</span> sc<span class=\"token punctuation\">.</span><span class=\"token function\">textFile</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"/opt/hadoop/ceshi.txt\"</span><span class=\"token punctuation\">)</span> <span class=\"token comment\">// 读取本地文件，注意修改本地文件的位置。</span>\n\n    val words <span class=\"token operator\">=</span> lines<span class=\"token punctuation\">.</span><span class=\"token function\">flatMap</span><span class=\"token punctuation\">(</span>_<span class=\"token punctuation\">.</span><span class=\"token function\">split</span><span class=\"token punctuation\">(</span><span class=\"token string\">\" \"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">filter</span><span class=\"token punctuation\">(</span>word <span class=\"token operator\">=</span><span class=\"token operator\">></span> word <span class=\"token operator\">!=</span> <span class=\"token string\">\" \"</span><span class=\"token punctuation\">)</span> <span class=\"token comment\">// 拆分单词，并过滤掉空格，当然还可以继续进行过滤，如去掉标点符号</span>\n    val pairs <span class=\"token operator\">=</span> words<span class=\"token punctuation\">.</span><span class=\"token function\">map</span><span class=\"token punctuation\">(</span>word <span class=\"token operator\">=</span><span class=\"token operator\">></span> <span class=\"token punctuation\">(</span>word<span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token comment\">// 在单词拆分的基础上对每个单词实例计数为1, 也就是 word => (word, 1)</span>\n    val wordscount <span class=\"token operator\">=</span> pairs<span class=\"token punctuation\">.</span><span class=\"token function\">reduceByKey</span><span class=\"token punctuation\">(</span>_ <span class=\"token operator\">+</span> _<span class=\"token punctuation\">)</span> <span class=\"token comment\">// 在每个单词实例计数为 1 的基础之上统计每个单词在文件中出现的总次数, 即 key 相同的 value 相加</span>\n    <span class=\"token comment\">// val wordscount = pairs.reduceByKey((v1, v2) => v1 + v2) // 等同于</span>\n    wordscount<span class=\"token punctuation\">.</span>collect<span class=\"token punctuation\">.</span><span class=\"token function\">foreach</span><span class=\"token punctuation\">(</span>println<span class=\"token punctuation\">)</span> <span class=\"token comment\">// 打印结果，使用 collect 会将集群中的数据收集到当前运行 drive 的机器上，需要保证单台机器能放得下所有数据</span>\n    sc<span class=\"token punctuation\">.</span><span class=\"token function\">stop</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token comment\">// 释放资源</span>\n\n  <span class=\"token punctuation\">}</span>\n    \n<span class=\"token punctuation\">}</span>\n\n</code></pre>\n"},{"type":"heading","depth":4,"payload":{"lines":[425,426]},"content":"<strong><em>出现的问题，搞了好几天，重装了好几次，最终通过更新JavaCA证书解决</em></strong>","children":[{"type":"fence","depth":5,"content":"<pre><code>[ERROR] Plugin org.apache.maven.plugins:maven-clean-plugin:3.2.0 or one of its dependencies could not be resolved: Failed to read artifact descriptor for org.apache.maven.plugins:maven-clean-plugin:jar:3.2.0: The following artifacts could not be resolved: org.apache.maven.plugins:maven-clean-plugin:pom:3.2.0 (absent): Could not transfer artifact org.apache.maven.plugins:maven-clean-plugin:pom:3.2.0 from/to aliyunmaven (https://maven.aliyun.com/repository/central): java.lang.RuntimeException: Unexpected error: java.security.InvalidAlgorithmParameterException: the trustAnchors parameter must be non-empty -&gt; [Help 1]\n</code></pre>\n"},{"type":"ordered_list","depth":5,"payload":{"lines":[461,505],"startIndex":1},"content":"","children":[{"type":"list_item","depth":6,"payload":{"lines":[461,462],"index":1},"content":"1. 首先确定Java运行环境所在的目录，一般是在 /usr/Java8/jvm/ 目录下，你可以执行以下命令查看已安装的Java版本："},{"type":"list_item","depth":6,"payload":{"lines":[467,468],"index":2},"content":"2. 进入Java运行环境所在目录，如："},{"type":"list_item","depth":6,"payload":{"lines":[473,474],"index":3},"content":"3. 进入 /jre/lib/security 目录："},{"type":"list_item","depth":6,"payload":{"lines":[479,480],"index":4},"content":"4. 备份当前的 cacerts 文件："},{"type":"list_item","depth":6,"payload":{"lines":[485,486],"index":5},"content":"5. 下载最新的 Java CA 证书文件："},{"type":"list_item","depth":6,"payload":{"lines":[495,496],"index":6},"content":"6. 运行以下命令更新 Java CA 证书："},{"type":"list_item","depth":6,"payload":{"lines":[503,504],"index":7},"content":"7. 输入 &quot;yes&quot; 确认安装该证书。"}]},{"type":"ordered_list","depth":5,"payload":{"lines":[509,513],"startIndex":8},"content":"","children":[{"type":"list_item","depth":6,"payload":{"lines":[509,510],"index":8},"content":"8. 重新启动 Maven，然后再次尝试使用阿里云镜像仓库进行依赖的下载和构建。"},{"type":"list_item","depth":6,"payload":{"lines":[511,512],"index":9},"content":"9. 能够下载，并且不再标红"}]}]}]},{"type":"heading","depth":3,"payload":{"lines":[517,518]},"content":"（9）在本地模式下运行"}]}]},{"type":"heading","depth":1,"payload":{"lines":[527,528]},"content":"三、<em>Spark</em>完全分布式环境配置","children":[{"type":"heading","depth":2,"payload":{"lines":[539,540]},"content":"（1）配置 slaves 文件","children":[{"type":"fence","depth":3,"content":"<pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token function\">cp</span> /opt/spark/conf/workers.template /opt/spark/conf/workers\n</code></pre>\n"},{"type":"fence","depth":3,"content":"<pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token function\">vim</span> /opt/spark/conf/workers\n</code></pre>\n"}]},{"type":"heading","depth":2,"payload":{"lines":[561,562]},"content":"（2）配置 spark-env.sh 文件","children":[{"type":"fence","depth":3,"content":"<pre class=\"language-shell\"><code class=\"language-shell\"><span class=\"token function\">cp</span> /opt/spark/conf/spark-env.sh.template /opt/spark/conf/spark-env.sh\n</code></pre>\n"},{"type":"fence","depth":3,"content":"<pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token function\">vim</span> /opt/spark/conf/spark-env.sh\n</code></pre>\n"}]},{"type":"heading","depth":2,"payload":{"lines":[583,584]},"content":"（3）配置好后，将 Master 主机上的/opt/spark 文件夹复制到各个节点上。","children":[{"type":"fence","depth":3,"content":"<pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token function\">scp</span> <span class=\"token parameter variable\">-r</span> /opt/spark/conf S2020212185:/opt/spark/\n</code></pre>\n"}]},{"type":"heading","depth":2,"payload":{"lines":[595,596]},"content":"启动 spark 集群","children":[{"type":"fence","depth":3,"content":"<pre class=\"language-shell\"><code class=\"language-shell\"><span class=\"token builtin class-name\">cd</span> /opt/spark/\nsbin/start-all.sh\n</code></pre>\n"}]},{"type":"heading","depth":2,"payload":{"lines":[616,617]},"content":"在浏览器上查看 <em>Spark</em> 独立集群管理器的集群信息","children":[{"type":"heading","depth":3,"payload":{"lines":[622,623]},"content":"<strong><em>出现的问题：WebUI总是显示不出来slave的worker</em></strong>"},{"type":"heading","depth":3,"payload":{"lines":[638,639]},"content":"<strong>然后成功运行！</strong>"}]}]},{"type":"heading","depth":1,"payload":{"lines":[644,645]},"content":"四、<em>Spark</em>完全分布运行 wordcount 程序","children":[{"type":"heading","depth":2,"payload":{"lines":[646,647]},"content":"1、创建工程：同单机伪分布的方法"},{"type":"heading","depth":2,"payload":{"lines":[652,653]},"content":"2、代码"},{"type":"heading","depth":2,"payload":{"lines":[666,667]},"content":"3、打包"},{"type":"heading","depth":2,"payload":{"lines":[672,673]},"content":"4、将 jar 包复制到 /opt/spark 文件夹中"},{"type":"heading","depth":2,"payload":{"lines":[686,687]},"content":"5、运行","children":[{"type":"fence","depth":3,"content":"<pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token builtin class-name\">cd</span> /opt/spark \nbin/spark-submit <span class=\"token parameter variable\">--class</span> org.bupt_2020212185_zy.wordcount <span class=\"token parameter variable\">--master</span> spark://10.243.164.219:7077 sparkwordcount_pro-1.0-SNAPSHOT.jar\n</code></pre>\n"}]},{"type":"heading","depth":2,"payload":{"lines":[723,724]},"content":"#######完美运行！######"}]}],"payload":{}},{})</script>
</body>
</html>
